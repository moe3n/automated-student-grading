# automated-student-grading
Text similarity measurement is one of the most vital issues in the AI/ML world. We are continually working to enhance our system to reduce human error while achieving high accuracy, and a written answer test—a form of assessment in which no response alternatives are offered and which is designed to gauge student’s level of topic understanding is being employed to achieve this goal. Manually evaluating the quality of the answers is a subjective and time-consuming operation. The purpose of this research is to create a text similarity system that will enable teachers to evaluate a script by comparing it to a sample response saved in the system to provide an automated approach of evaluating text responses based on Jaro-Winkler. The calculated results are in real time to a remote server, the results in this case must be relevant and obtained very quickly. The objective is to not only shorten the time and eliminate any risk of biasness but also explores the potential of text similarity-based grading to improve the grading process.
